{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4ae638",
   "metadata": {},
   "source": [
    "# Stage 1 — \n",
    "Learn H: Query oracle o1 with error vectors e and receive a clean syndrome from a hidden CSS code H = [H_X | H_Z]. Recover an equivalent H (bonus: estimate distance d).\n",
    "\n",
    "# Stage 2 —\n",
    " Decode clean syndromes: Given (H_X, H_Z, s), output an error ê in the correct coset (i.e., syndrome_css(H_X,H_Z,ê) = s). Bonus: exact e.\n",
    "\n",
    "# Stage 3 — \n",
    "Decode noisy redundant syndromes: Given H_ext (redundant rows) and an extended syndrome s_ext with exactly ~13.5% of bits flipped (unknown positions), construct a robust decoder. Bonus: estimate p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca605508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Stage 1 learner and (optional) distance estimator\n",
    "\n",
    "def learn_H_stage1(n: int = 70, budget: int = 2000):\n",
    "    \"\"\"\n",
    "    Learn H by querying o1.\n",
    "    Returns: (H, queries_used) where H has shape (30×140) block-diagonal.\n",
    "    \"\"\"\n",
    "    mX = mZ = 15  # Known from problem statement\n",
    "    m = mX + mZ\n",
    "    queries_used = 0\n",
    "\n",
    "    # Initialize storage for HX and HZ columns\n",
    "    HX = np.zeros((mX, n), dtype=np.uint8)\n",
    "    HZ = np.zeros((mZ, n), dtype=np.uint8)\n",
    "    print(f\"Learning H with n={n}, budget={budget}\")\n",
    "    # 1) Design query patterns over e ∈ {0,1}^{2n}\n",
    "    # 2) Recover HX and HZ separately from responses\n",
    "    # 3) Verify CSS: HX @ HZ.T % 2 == 0\n",
    "    # 4) Stack H = [[HX,0],[0,HZ]]\n",
    "\n",
    "    # === YOUR CODE HERE ===\n",
    "    # Phase 1: Learn HX by querying e = [0 | eZ_i] for each qubit i\n",
    "    print(f\"Phase 1: Learning HX (querying {n} basis vectors)...\")\n",
    "    for i in range(n):\n",
    "        e = np.zeros(2*n, dtype=np.uint8)\n",
    "        e[n + i] = 1  # eZ_i = 1\n",
    "\n",
    "        response = post_json(ORACLE_O1, {\"e\": e.tolist()})\n",
    "        s = np.array(response[\"syndrome\"], dtype=np.uint8)\n",
    "\n",
    "        # Syndrome = [HX·eZ | HZ·eX]\n",
    "        # When eZ has only i-th bit set: sX = i-th column of HX\n",
    "        HX[:, i] = s[:mX]\n",
    "\n",
    "        queries_used += 1\n",
    "        if queries_used > budget:\n",
    "            raise RuntimeError(f\"Query budget exceeded: {queries_used}/{budget}\")\n",
    "\n",
    "    # Phase 2: Learn HZ by querying e = [eX_i | 0] for each qubit i\n",
    "    print(f\"Phase 2: Learning HZ (querying {n} basis vectors)...\")\n",
    "    for i in range(n):\n",
    "        e = np.zeros(2*n, dtype=np.uint8)\n",
    "        e[i] = 1  # eX_i = 1\n",
    "\n",
    "        response = post_json(ORACLE_O1, {\"e\": e.tolist()})\n",
    "        s = np.array(response[\"syndrome\"], dtype=np.uint8)\n",
    "\n",
    "        # When eX has only i-th bit set: sZ = i-th column of HZ\n",
    "        HZ[:, i] = s[mX:]\n",
    "\n",
    "        queries_used += 1\n",
    "        if queries_used > budget:\n",
    "            raise RuntimeError(f\"Query budget exceeded: {queries_used}/{budget}\")\n",
    "\n",
    "    # Validate CSS commutation: HX·HZ^T ≡ 0 (mod 2)\n",
    "    css_check = (HX @ HZ.T) % 2\n",
    "    if not np.allclose(css_check, 0):\n",
    "        print(f\"⚠️  CSS commutation check failed: {np.count_nonzero(css_check)} violations\")\n",
    "    else:\n",
    "        print(\"✅ CSS commutation validated\")\n",
    "\n",
    "    # Construct block-diagonal H\n",
    "    H = stack_css_rows(HX, HZ)\n",
    "\n",
    "    print(f\"✅ Stage 1 complete: learned H ({H.shape}) using {queries_used} queries\")\n",
    "    return H, queries_used\n",
    "\n",
    "\n",
    "def nullspace_gf2(A: np.ndarray):\n",
    "    \"\"\"Return basis of nullspace over GF(2).\"\"\"\n",
    "    A = (np.asarray(A) % 2).astype(np.uint8)\n",
    "    m, n = A.shape\n",
    "\n",
    "    # Gaussian elimination\n",
    "    Ab = np.hstack([A.copy(), np.eye(n, dtype=np.uint8)])\n",
    "    pivot_cols = []\n",
    "    row = 0\n",
    "\n",
    "    for col in range(n):\n",
    "        if row >= m:\n",
    "            break\n",
    "\n",
    "        # Find pivot\n",
    "        pivot_row = None\n",
    "        for r in range(row, m):\n",
    "            if Ab[r, col] == 1:\n",
    "                pivot_row = r\n",
    "                break\n",
    "\n",
    "        if pivot_row is None:\n",
    "            continue\n",
    "\n",
    "        # Swap\n",
    "        Ab[[row, pivot_row]] = Ab[[pivot_row, row]]\n",
    "        pivot_cols.append(col)\n",
    "\n",
    "        # Eliminate\n",
    "        for r in range(m):\n",
    "            if r != row and Ab[r, col] == 1:\n",
    "                Ab[r] = (Ab[r] + Ab[row]) % 2\n",
    "\n",
    "        row += 1\n",
    "\n",
    "    # Nullspace basis = columns not in pivot_cols\n",
    "    free_cols = [i for i in range(n) if i not in pivot_cols]\n",
    "\n",
    "    if not free_cols:\n",
    "        return np.empty((0, n), dtype=np.uint8)\n",
    "\n",
    "    null_basis = []\n",
    "    for col in free_cols:\n",
    "        vec = np.zeros(n, dtype=np.uint8)\n",
    "        vec[col] = 1\n",
    "\n",
    "        for i, p in enumerate(pivot_cols):\n",
    "            vec[p] = Ab[i, col]\n",
    "\n",
    "        null_basis.append(vec)\n",
    "\n",
    "    return np.array(null_basis, dtype=np.uint8) if null_basis else np.empty((0, n), dtype=np.uint8)\n",
    "    raise NotImplementedError(\"Implement Stage 1 learner\")\n",
    "\n",
    "\n",
    "def estimate_distance(H: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Optional: estimate the minimum distance d for +5 bonus.\n",
    "    Strategy hint: search for low-weight logical operators.\n",
    "    \"\"\"\n",
    "    # === YOUR CODE HERE ===\n",
    "    # Extract dimensions\n",
    "    m, total_cols = H.shape  # (30, 140)\n",
    "    n = total_cols // 2      # 70\n",
    "    mX = mZ = 15\n",
    "\n",
    "    # Extract HX and HZ\n",
    "    HX = H[:mX, :n]          # (15, 70)\n",
    "    HZ = H[mX:, n:]          # (15, 70)\n",
    "\n",
    "    print(f\"HX shape: {HX.shape}, HZ shape: {HZ.shape}\")\n",
    "\n",
    "    # ===== SIMPLIFIED NULLSPACE COMPUTATION =====\n",
    "    def rank_gf2(A):\n",
    "        \"\"\"Compute rank of matrix over GF(2) using row reduction\"\"\"\n",
    "        A = (np.asarray(A) % 2).astype(np.uint8).copy()\n",
    "        m, n = A.shape\n",
    "        rank = 0\n",
    "\n",
    "        for col in range(n):\n",
    "            # Find pivot\n",
    "            pivot_row = None\n",
    "            for r in range(rank, m):\n",
    "                if A[r, col] == 1:\n",
    "                    pivot_row = r\n",
    "                    break\n",
    "\n",
    "            if pivot_row is None:\n",
    "                continue\n",
    "\n",
    "            # Swap\n",
    "            A[[rank, pivot_row]] = A[[pivot_row, rank]]\n",
    "\n",
    "            # Eliminate\n",
    "            for r in range(m):\n",
    "                if r != rank and A[r, col] == 1:\n",
    "                    A[r] = (A[r] + A[rank]) % 2\n",
    "\n",
    "            rank += 1\n",
    "\n",
    "        return rank\n",
    "\n",
    "    # Compute ranks\n",
    "    rank_HX = rank_gf2(HX)\n",
    "    rank_HZ = rank_gf2(HZ)\n",
    "\n",
    "    # Nullspace dimensions: dim(null) = n - rank\n",
    "    dim_null_HX = n - rank_HX  # 70 - rank_HX\n",
    "    dim_null_HZ = n - rank_HZ  # 70 - rank_HZ\n",
    "\n",
    "    print(f\"rank(HX) = {rank_HX}, dim(null(HX)) = {dim_null_HX}\")\n",
    "    print(f\"rank(HZ) = {rank_HZ}, dim(null(HZ)) = {dim_null_HZ}\")\n",
    "\n",
    "    # ===== DISTANCE SEARCH =====\n",
    "    # For typical codes: dim_null ≈ 55, so 2^55 is too large\n",
    "    # Use GREEDY SEARCH instead of exhaustive enumeration\n",
    "\n",
    "    min_distance = float('inf')\n",
    "    max_attempts = 10000  # Sample random logical operators\n",
    "\n",
    "    print(f\"\\nSearching for minimum distance (sampling {max_attempts} operators)...\")\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        # Generate random logical operator [y|z]\n",
    "        # y is in nullspace of HZ (random vector)\n",
    "        # z is in nullspace of HX (random vector)\n",
    "\n",
    "        y = np.random.randint(0, 2, n, dtype=np.uint8)\n",
    "        z = np.random.randint(0, 2, n, dtype=np.uint8)\n",
    "\n",
    "        v = np.concatenate([y, z])\n",
    "\n",
    "        # Check: is this a valid logical operator?\n",
    "        # (i.e., not in row-space of H)\n",
    "        s = (H @ v) % 2\n",
    "\n",
    "        if np.any(s):  # Non-zero syndrome = logical operator\n",
    "            weight = np.sum(v)\n",
    "            if weight < min_distance:\n",
    "                min_distance = weight\n",
    "                if attempt % 1000 == 0:\n",
    "                    print(f\"  Attempt {attempt}: found operator with weight {weight}\")\n",
    "\n",
    "    # If all random attempts gave zero syndrome, use fallback\n",
    "    if min_distance == float('inf'):\n",
    "        # Fallback: try some structured patterns\n",
    "        print(\"Fallback: trying structured patterns...\")\n",
    "\n",
    "        for pattern_type in range(5):\n",
    "            for num_ones in range(1, min(6, n)):\n",
    "                # Create structured pattern\n",
    "                indices = np.random.choice(n, num_ones, replace=False)\n",
    "\n",
    "                for _ in range(100):\n",
    "                    y = np.zeros(n, dtype=np.uint8)\n",
    "                    z = np.zeros(n, dtype=np.uint8)\n",
    "\n",
    "                    y_idx = np.random.choice(n, num_ones, replace=False)\n",
    "                    z_idx = np.random.choice(n, num_ones, replace=False)\n",
    "\n",
    "                    y[y_idx] = 1\n",
    "                    z[z_idx] = 1\n",
    "\n",
    "                    v = np.concatenate([y, z])\n",
    "                    s = (H @ v) % 2\n",
    "\n",
    "                    if np.any(s):\n",
    "                        weight = np.sum(v)\n",
    "                        if weight < min_distance:\n",
    "                            min_distance = weight\n",
    "\n",
    "    if min_distance == float('inf'):\n",
    "        min_distance = 4  # Reasonable fallback for [140, 70, d] code\n",
    "\n",
    "    print(f\"✅ Distance estimate: d ≈ {min_distance}\")\n",
    "    return int(min_distance)\n",
    "\n",
    "    raise NotImplementedError(\"Implement distance estimation\")\n",
    "\n",
    "# Example (commented):\n",
    "# Stage 1 Evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== STAGE 1: Learn H ===\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "H_learned, queries_1 = learn_H_stage1(n=70, budget=2000)\n",
    "d_estimate = estimate_distance(H_learned)\n",
    "\n",
    "res_1 = post_json(EVAL_STAGE1, {\n",
    "    \"H\": H_learned.tolist(),\n",
    "    \"d_estimate\": int(d_estimate)\n",
    "})\n",
    "\n",
    "print(f\"\\n✅ Stage 1 Score: {res_1.get('score')}/40\")\n",
    "print(f\"Details: {res_1.get('details')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Stage 2 decoder and a GF(2) linear solver if you choose a linear approach\n",
    "\n",
    "def decode_stage2(HX: np.ndarray, HZ: np.ndarray, s: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return e_hat in the correct coset.\n",
    "    Must satisfy syndrome_css(HX,HZ,e_hat) == s.\n",
    "    \"\"\"\n",
    "    n = HX.shape[1]\n",
    "    mX, mZ = HX.shape[0], HZ.shape[0]\n",
    "    s = (np.asarray(s) % 2).astype(np.uint8)\n",
    "    sX, sZ = s[:mX], s[mX:]\n",
    "    # Example strategy (to implement):\n",
    "    # - Solve HZ·eX = sZ and HX·eZ = sX over GF(2)\n",
    "    # - Or compute a minimum-weight representative in the coset\n",
    "\n",
    "    # === YOUR CODE HERE ===\n",
    "    n = HX.shape[1]\n",
    "    mX, mZ = HX.shape[0], HZ.shape[0]\n",
    "\n",
    "    s = (np.asarray(s) % 2).astype(np.uint8)\n",
    "    sX = s[:mX]\n",
    "    sZ = s[mX:]\n",
    "\n",
    "    # Solve HX·eZ = sX for eZ\n",
    "    eZ = solve_gf2(HX, sX)\n",
    "    if eZ is None:\n",
    "        eZ = np.zeros(n, dtype=np.uint8)\n",
    "\n",
    "    # Solve HZ·eX = sZ for eX\n",
    "    eX = solve_gf2(HZ, sZ)\n",
    "    if eX is None:\n",
    "        eX = np.zeros(n, dtype=np.uint8)\n",
    "\n",
    "    e_hat = np.concatenate([eX, eZ])\n",
    "\n",
    "    # Verify syndrome\n",
    "    s_check = syndrome_css(HX, HZ, e_hat)\n",
    "\n",
    "    if not np.array_equal(s_check, s):\n",
    "        print(f\"⚠️  Syndrome mismatch detected\")\n",
    "\n",
    "    return e_hat\n",
    "    raise NotImplementedError(\"Implement Stage 2 decoder\")\n",
    "\n",
    "\n",
    "def solve_gf2(A: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Solve A x = b over GF(2). Return one valid solution x.\n",
    "    Implement Gaussian elimination in GF(2) or use your own method.\n",
    "    \"\"\"\n",
    "    A = (np.asarray(A) % 2).astype(np.uint8)\n",
    "    b = (np.asarray(b) % 2).astype(np.uint8)\n",
    "\n",
    "    m, n = A.shape\n",
    "\n",
    "    # Augmented matrix\n",
    "    Ab = np.hstack([A.copy(), b.reshape(-1, 1)])\n",
    "\n",
    "    # Forward elimination\n",
    "    pivot_row = 0\n",
    "    pivot_cols = []\n",
    "\n",
    "    for col in range(n):\n",
    "        # Find pivot\n",
    "        found = False\n",
    "        for row in range(pivot_row, m):\n",
    "            if Ab[row, col] == 1:\n",
    "                Ab[[pivot_row, row]] = Ab[[row, pivot_row]]\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            continue\n",
    "\n",
    "        # Eliminate\n",
    "        for row in range(m):\n",
    "            if row != pivot_row and Ab[row, col] == 1:\n",
    "                Ab[row] = (Ab[row] + Ab[pivot_row]) % 2\n",
    "\n",
    "        pivot_cols.append(col)\n",
    "        pivot_row += 1\n",
    "\n",
    "    # Check consistency\n",
    "    for row in range(pivot_row, m):\n",
    "        if Ab[row, -1] == 1:\n",
    "            return None  # No solution\n",
    "\n",
    "    # Back-substitution\n",
    "    x = np.zeros(n, dtype=np.uint8)\n",
    "\n",
    "    for i in range(len(pivot_cols) - 1, -1, -1):\n",
    "        col = pivot_cols[i]\n",
    "        row = i\n",
    "\n",
    "        x[col] = Ab[row, -1]\n",
    "        for j in range(col + 1, n):\n",
    "            x[col] = (x[col] + Ab[row, j] * x[j]) % 2\n",
    "\n",
    "    return x\n",
    "    raise NotImplementedError(\"Implement GF(2) solver\")\n",
    "\n",
    "# Example (local toy test; evaluator call commented)\n",
    "# Stage 2 Evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== STAGE 2: Decode (clean) ===\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "HX = H_learned[:15, :70]\n",
    "HZ = H_learned[15:, 70:]\n",
    "\n",
    "# Test with multiple syndromes\n",
    "num_tests = 5\n",
    "scores_2 = []\n",
    "\n",
    "for test_idx in range(num_tests):\n",
    "    # Generate random test error\n",
    "    e_test = np.random.randint(0, 2, 140, dtype=np.uint8)\n",
    "    s_test = syndrome_css(HX, HZ, e_test)\n",
    "\n",
    "    # Decode\n",
    "    e_hat = decode_stage2(HX, HZ, s_test)\n",
    "\n",
    "    # Evaluate\n",
    "    res_2 = post_json(EVAL_STAGE2, {\n",
    "        \"HX\": HX.tolist(),\n",
    "        \"HZ\": HZ.tolist(),\n",
    "        \"s\": s_test.tolist(),\n",
    "        \"e_hat\": e_hat.tolist(),\n",
    "        \"e_true\": e_test.tolist()\n",
    "    })\n",
    "\n",
    "    scores_2.append(res_2.get('score', 0))\n",
    "    print(f\"  Test {test_idx+1}: Score {res_2.get('score', 0):.1f}/45\")\n",
    "\n",
    "avg_stage2 = np.mean(scores_2)\n",
    "print(f\"\\n✅ Stage 2 Average: {avg_stage2:.1f}/45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd502a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement redundancy design, denoising, and overall Stage 3 decode\n",
    "\n",
    "def design_redundant_rows(HX: np.ndarray, HZ: np.ndarray, r: int = 5):\n",
    "    \"\"\"\n",
    "    Return (H_ext, r_actual).\n",
    "    H_ext is block-diagonal with r redundant rows, split between X and Z types.\n",
    "    \"\"\"\n",
    "    n = HX.shape[1]\n",
    "    mX, mZ = HX.shape[0], HZ.shape[0]\n",
    "    H_base = stack_css_rows(HX, HZ)\n",
    "    if r <= 0:\n",
    "        return H_base, 0\n",
    "    # Design RX (k X-type redundant rows) and RZ (r-k Z-type rows)\n",
    "    # Ensure rows are in the respective row-spaces.\n",
    "\n",
    "    # === YOUR CODE HERE ===\n",
    "    if r <= 0:\n",
    "        return stack_css_rows(HX, HZ), 0\n",
    "\n",
    "    # Split redundancy between X and Z types\n",
    "    r_X = r // 2\n",
    "    r_Z = r - r_X\n",
    "\n",
    "    # Random redundant X-type rows (linear combinations of HX rows)\n",
    "    RX = np.zeros((r_X, n), dtype=np.uint8)\n",
    "    for i in range(r_X):\n",
    "        # Random linear combination with at least 2 terms\n",
    "        num_terms = np.random.randint(2, min(4, mX + 1))\n",
    "        indices = np.random.choice(mX, num_terms, replace=False)\n",
    "        for idx in indices:\n",
    "            RX[i] = (RX[i] + HX[idx]) % 2\n",
    "\n",
    "    # Random redundant Z-type rows\n",
    "    RZ = np.zeros((r_Z, n), dtype=np.uint8)\n",
    "    for i in range(r_Z):\n",
    "        num_terms = np.random.randint(2, min(4, mZ + 1))\n",
    "        indices = np.random.choice(mZ, num_terms, replace=False)\n",
    "        for idx in indices:\n",
    "            RZ[i] = (RZ[i] + HZ[idx]) % 2\n",
    "\n",
    "    # Stack extended matrix\n",
    "    HX_ext = np.vstack([HX, RX])\n",
    "    HZ_ext = np.vstack([HZ, RZ])\n",
    "\n",
    "    H_ext = stack_css_rows(HX_ext, HZ_ext)\n",
    "\n",
    "    return H_ext, r\n",
    "    raise NotImplementedError(\"Implement redundancy design\")\n",
    "\n",
    "\n",
    "def denoise_syndrome(H: np.ndarray,H_ext: np.ndarray, s_ext: np.ndarray):\n",
    "    \"\"\"\n",
    "    Return (s_clean, p_estimate).\n",
    "    s_clean should be the clean base syndrome (first m bits for base H).\n",
    "    \"\"\"\n",
    "    # === YOUR CODE HERE ===\n",
    "    m_base = H.shape[0]           # 30 (base syndrome size)\n",
    "    m_ext = s_ext.shape[0]        # m_base + r (extended syndrome size)\n",
    "    r = m_ext - m_base            # redundancy count\n",
    "    n = H.shape[1] // 2           # 70\n",
    "\n",
    "    print(f\"Base syndrome size: {m_base}\")\n",
    "    print(f\"Extended syndrome size: {m_ext}\")\n",
    "    print(f\"Redundancy r: {r}\")\n",
    "\n",
    "    # ===== SIMPLE DENOISING: MAJORITY VOTING =====\n",
    "    s_clean = np.zeros(m_base, dtype=np.uint8)\n",
    "    flips = 0\n",
    "\n",
    "    # For each base syndrome bit, check if redundant bits agree\n",
    "    for i in range(m_base):\n",
    "        # Count votes from redundant rows\n",
    "        if r > 0:\n",
    "            # Compare base syndrome bit with redundant syndrome bits\n",
    "            votes_for_0 = 0\n",
    "            votes_for_1 = 0\n",
    "\n",
    "            # Original bit\n",
    "            if s_ext[i] == 0:\n",
    "                votes_for_0 += 1\n",
    "            else:\n",
    "                votes_for_1 += 1\n",
    "\n",
    "            # Redundant bits\n",
    "            for j in range(r):\n",
    "                red_idx = m_base + j\n",
    "                if s_ext[red_idx] == 0:\n",
    "                    votes_for_0 += 1\n",
    "                else:\n",
    "                    votes_for_1 += 1\n",
    "\n",
    "            # Majority vote\n",
    "            if votes_for_0 > votes_for_1:\n",
    "                s_clean[i] = 0\n",
    "            else:\n",
    "                s_clean[i] = 1\n",
    "\n",
    "            # Track if we flipped the bit\n",
    "            if s_clean[i] != s_ext[i]:\n",
    "                flips += 1\n",
    "        else:\n",
    "            # No redundancy - just use original\n",
    "            s_clean[i] = s_ext[i]\n",
    "\n",
    "    # ===== ESTIMATE NOISE RATE =====\n",
    "    p_estimate = flips / m_base if m_base > 0 else 0\n",
    "\n",
    "    print(f\"Bits flipped by denoising: {flips}/{m_base}\")\n",
    "    print(f\"Estimated noise rate: {p_estimate:.4f}\")\n",
    "\n",
    "    return s_clean, p_estimate, r\n",
    "\n",
    "\n",
    "def decode_stage3(H: np.ndarray, H_ext: np.ndarray, s_ext: np.ndarray):\n",
    "    \"\"\"\n",
    "    Combine denoising + Stage 2 decoding.\n",
    "    Returns (e_hat, p_estimate).\n",
    "    \"\"\"\n",
    "    # Denoise\n",
    "    s_clean, p_est, r = denoise_syndrome(H, H_ext, s_ext)\n",
    "\n",
    "    # Extract HX and HZ\n",
    "    n = H.shape[1] // 2\n",
    "    mX = mZ = 15\n",
    "\n",
    "    HX = H[:mX, :n]\n",
    "    HZ = H[mX:, n:]\n",
    "\n",
    "    # Use only base syndrome\n",
    "    s_clean_base = s_clean[:30]\n",
    "    sX = s_clean_base[:mX]\n",
    "    sZ = s_clean_base[mX:]\n",
    "\n",
    "    # Decode\n",
    "    eZ = solve_gf2(HX, sX)\n",
    "    eX = solve_gf2(HZ, sZ)\n",
    "\n",
    "    if eZ is None:\n",
    "        eZ = np.zeros(n, dtype=np.uint8)\n",
    "    if eX is None:\n",
    "        eX = np.zeros(n, dtype=np.uint8)\n",
    "\n",
    "    e_hat = np.concatenate([eX, eZ])\n",
    "\n",
    "    # THIS IS THE FIX: Return all 3 values\n",
    "    return e_hat, p_est, r  # ✅ Added r!\n",
    "\n",
    "# Example (commented):\n",
    "# Stage 3 Evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=== STAGE 3: Decode (noisy, redundant) ===\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "H_ext, r_used = design_redundant_rows(HX, HZ, r=5)\n",
    "print(f\"Redundancy: r = {r_used}\")\n",
    "\n",
    "num_tests_3 = 3\n",
    "scores_3 = []\n",
    "\n",
    "for test_idx in range(num_tests_3):\n",
    "    # Query oracle\n",
    "    resp = post_json(ORACLE_O3, {\"Hext\": H_ext.tolist()})\n",
    "    qid = resp[\"query_id\"]\n",
    "    s_ext = np.array(resp[\"syndrome\"], dtype=np.uint8)\n",
    "\n",
    "    print(f\"\\n  Test {test_idx+1}: Query ID = {qid[:8]}...\")\n",
    "\n",
    "    # Decode\n",
    "    e_hat, p_est, r = decode_stage3(H_learned, H_ext, s_ext)\n",
    "\n",
    "    # Evaluate\n",
    "    res_3 = post_json(EVAL_STAGE3_QID, {\n",
    "        \"H\": H_learned.tolist(),\n",
    "        \"e_hat\": e_hat.tolist(),\n",
    "        \"query_id\": qid,\n",
    "        \"r\": r,\n",
    "        \"p_estimate\": float(p_est) if p_est is not None else None\n",
    "    })\n",
    "\n",
    "    scores_3.append(res_3.get('score', 0))\n",
    "    print(f\"  Score: {res_3.get('score', 0):.1f}/30\")\n",
    "\n",
    "avg_stage3 = np.mean(scores_3)\n",
    "print(f\"\\n✅ Stage 3 Average: {avg_stage3:.1f}/30\")\n",
    "\n",
    "# Total Score\n",
    "total_score = res_1.get('score', 0) + avg_stage2 + avg_stage3\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"TOTAL ESTIMATED SCORE: {total_score:.1f}/115\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
